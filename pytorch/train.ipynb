{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "import torch\n", "from torch.utils.data import DataLoader\n", "from torchvision import datasets, transforms\n", "from torchvision.utils import make_grid"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from sklearn.metrics import confusion_matrix\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from unet import unet"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gpu_enabled = torch.cuda.is_available()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["means = [0.485, 0.456, 0.406]  # mean of the imagenet dataset for normalizing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stds = [0.229, 0.224, 0.225] # standard deviance of the imagenet dataset for normalizing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def deNormalize(img,means=means,stds=stds):\n", "    red = img[...,0] * stds[0] + means[0]\n", "    green = img[...,1] * stds[1] + means[1]\n", "    blue = img[...,2] * stds[2] + means[2]\n", "    denormed = np.stack([red,green,blue],axis=2)\n", "    return denormed"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Generate dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((224,224)), transforms.Normalize(means,stds) ])\n", "transform_target = transforms.Compose([transforms.ToTensor(),transforms.Resize((224,224)) ])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data = datasets.VOCSegmentation(root='./Data', image_set='train', download=True, transform=transform, target_transform=transform_target)\n", "val_data = datasets.VOCSegmentation(root='./Data', image_set='val', download=True, transform=transform, target_transform=transform_target)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(train_data)\n", "print(val_data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = DataLoader(train_data, batch_size=10, shuffle=True,pin_memory=gpu_enabled)\n", "val_loader = DataLoader(val_data, batch_size=10, shuffle=False,pin_memory=gpu_enabled)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain step"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_step(train_loader,model,criterion,opt,train_losses,train_corr):\n", "    model.train()\n", "    for b,(img,label) in enumerate(train_loader):\n", "        if gpu_enabled:\n", "            img = img.cuda()\n", "            label = label.cuda()\n", "        b += 1\n", "        opt.zero_grad()\n", "        y = model(img)\n", "        loss = criterion(y,torch.squeeze(label,dim=1))\n", "        loss.backward()\n", "        opt.step()\n", "        if b%10 == 0:\n", "            print(f\"Batch : {b} , Train Loss : {loss} Train Acc \")\n", "    train_losses.append(loss.item())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", "#simply used to visualize a few examples\n", "for b,(img_batch,label_batch) in enumerate(train_loader):\n", "    break"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img = deNormalize(np.transpose(img_batch[0,...],(1,2,0)))\n", "label = np.squeeze(np.transpose(label_batch[0,...],(1,2,0)),axis=2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_example(img,label):\n", "    plt.figure()\n", "    plt.subplot(1,2,1)\n", "    plt.imshow(img)\n", "    plt.subplot(1,2,2)\n", "    plt.imshow(label)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plot_example(img,label)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if gpu_enabled:\n", "    model = unet(3,20).cuda()\n", "else:\n", "    model = unet(3,20)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_losses = []\n", "train_corr = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = torch.nn.CrossEntropyLoss()\n", "opt = torch.optim.Adam(model.parameters(),lr = 0.001)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["EPOCHS = 2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for epoch in range(EPOCHS):\n", "    train_step(train_loader,model,criterion,opt,train_losses,train_corr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["imply used to visualize a few examples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for img_batch,label_batch in val_loader:\n", "    break"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img = deNormalize(np.transpose(img_batch[0,...],(1,2,0)))\n", "label = np.squeeze(np.transpose(label_batch[0,...],(1,2,0)),axis=2)\n", "plot_example(img,label)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with torch.no_grad():\n", "    y = model(img_batch[0,...].view(-1,...))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y = deNormalize(np.transpose(y[0,...],(1,2,0)))\n", "plot_example(y,label)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(train_losses)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}